{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2f2f3f",
   "metadata": {},
   "source": [
    "# 1. Carga y Limpieza del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfe16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 5318165 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo\n",
    "with open(\"Gutenberg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Eliminar encabezados/pies del archivo de Gutenberg\n",
    "start = text.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
    "end = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
    "if start != -1 and end != -1:\n",
    "    text = text[start:end]\n",
    "\n",
    "# Limpiar saltos de línea dobles y espacios extra\n",
    "text = text.replace('\\r', '').replace('\\n\\n', '\\n').strip()\n",
    "print(f\"Longitud del texto: {len(text)} caracteres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3a399",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento a nivel de caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7faeabff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario de 100 caracteres\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Crear vocabulario\n",
    "chars = sorted(set(text))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(f\"Vocabulario de {vocab_size} caracteres\")\n",
    "\n",
    "# Convertir texto a enteros\n",
    "encoded = [char2idx[c] for c in text]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2b6c0",
   "metadata": {},
   "source": [
    "# 3. Crear secuencias de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e1197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de secuencias: 5318125\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 40\n",
    "step = 1\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(encoded) - sequence_length, step):\n",
    "    X.append(encoded[i:i + sequence_length])\n",
    "    y.append(encoded[i + sequence_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "print(f\"Total de secuencias: {len(X)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7ff1b",
   "metadata": {},
   "source": [
    "# 4. Modelo RNN con LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa201d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gerar\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │         \u001b[38;5;34m5,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m91,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,900\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,548</span> (427.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,548\u001b[0m (427.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,548</span> (427.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,548\u001b[0m (427.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=sequence_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.build(input_shape=(None, sequence_length))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888fddfe",
   "metadata": {},
   "source": [
    "# 5. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09cd951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2780s\u001b[0m 33ms/step - loss: 1.9811\n",
      "Epoch 2/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2744s\u001b[0m 33ms/step - loss: 1.5972\n",
      "Epoch 3/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2797s\u001b[0m 33ms/step - loss: 1.5434\n",
      "Epoch 4/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2745s\u001b[0m 33ms/step - loss: 1.5170\n",
      "Epoch 5/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2741s\u001b[0m 33ms/step - loss: 1.5009\n",
      "Epoch 6/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2776s\u001b[0m 33ms/step - loss: 1.4911\n",
      "Epoch 7/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2795s\u001b[0m 34ms/step - loss: 1.4823\n",
      "Epoch 8/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2803s\u001b[0m 34ms/step - loss: 1.4767\n",
      "Epoch 9/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2812s\u001b[0m 34ms/step - loss: 1.4712\n",
      "Epoch 10/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2841s\u001b[0m 34ms/step - loss: 1.4681\n",
      "Epoch 11/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2864s\u001b[0m 34ms/step - loss: 1.4655\n",
      "Epoch 12/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2884s\u001b[0m 35ms/step - loss: 1.4614\n",
      "Epoch 13/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2911s\u001b[0m 35ms/step - loss: 1.4594\n",
      "Epoch 14/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2843s\u001b[0m 34ms/step - loss: 1.4592\n",
      "Epoch 15/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3094s\u001b[0m 37ms/step - loss: 1.4580\n",
      "Epoch 16/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2819s\u001b[0m 34ms/step - loss: 1.4559\n",
      "Epoch 17/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3005s\u001b[0m 36ms/step - loss: 1.4558\n",
      "Epoch 18/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3225s\u001b[0m 39ms/step - loss: 1.4534\n",
      "Epoch 19/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3291s\u001b[0m 40ms/step - loss: 1.4515\n",
      "Epoch 20/20\n",
      "\u001b[1m83096/83096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3547s\u001b[0m 43ms/step - loss: 1.4519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e89f226cf0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f15ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"poem_generator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89cefe",
   "metadata": {},
   "source": [
    "# 6. Funcion para muestreo con temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24003445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds + 1e-8) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(preds), p=preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3b55a",
   "metadata": {},
   "source": [
    "# 7. Generacion de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db6bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed, length=400, temperature=1.0, force_end_punctuation=True):\n",
    "    generated = seed\n",
    "    seed_encoded = [char2idx[c] for c in seed]\n",
    "\n",
    "    for _ in range(length):\n",
    "        padded = pad_sequences([seed_encoded[-sequence_length:]], maxlen=sequence_length)\n",
    "        preds = model.predict(padded, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = idx2char[next_index]\n",
    "        generated += next_char\n",
    "        seed_encoded.append(next_index)\n",
    "\n",
    "    if force_end_punctuation:\n",
    "        # Buscar desde el final hacia atrás el primer '.', '?', o '!'\n",
    "        for i in range(len(generated)-1, -1, -1):\n",
    "            if generated[i] in ['.', '!', '?']:\n",
    "                generated = generated[:i+1]\n",
    "                break\n",
    "        else:\n",
    "            # Si no se encontró puntuación final, agregamos '.'\n",
    "            generated += '.'\n",
    "\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793be06",
   "metadata": {},
   "source": [
    "# 8. Prueba de Generacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d128c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun about\n",
      "Wourrion a grown doth barge did, ’righs,\n",
      "And do him a whomp, to speak for it again for thee.\n",
      "Go Olivy.\n",
      "SECOND GENTLEMAN.\n",
      "Tillance upon thy Richard, y’ell in grave?\n",
      "LODin Firief’s Mortives. Arterp, and pleat me\n",
      "These death yet grurd on me and day,\n",
      "As thy most hearts\n",
      "As i’ th’ dead’s all. No, and the hand?\n",
      "LAOL.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"The sun \", length=400, temperature=1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
